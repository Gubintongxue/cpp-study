# select poll epoll 区别

# epoll 优势

那这节课呢，给大家把这个lO复用啊，尤其是这个epoll啊。好，我们来总结一下啊。那么，总结它之前呢？

我们肯定要是跟select poll的这个对比一下，

我们把它们两个的缺点也说一下啊，为什么我们最终要使用epoll？

像这个libevent呀，muduo库啊，网络库都会使用这个epoll

像JAVA里边的这个多路复用的这个selector选择器啊，其底层在操作系统层面，

它调用的也是epoll啊，在linux下调用的也是epoll，

在WINDOWS它调用的是lcp啊。

WINDOWS的系统我们就不说了。



所以epoll非常重要啊，应该也是面试的时候呢，我们同学们被问的比较多的啊。

在上边儿讲这个reactor模型的时候就给大家说了这个多路事件分发器啊，

在这儿你就把它想成这个epoll。对不对啊？

上节课呢，给大家画这个muduo库的这个multiplex reactors的话呢，

事件分发器简单理解为epoll

我们说这个它上面这个图的reactor相当于就是把这个我们上边这个reactor跟事件分发器合二为一了是吧？

这个相当于就是那个IO线程对吧？

IO线程的那个eventloop，它主要做的是新用户的连接accept嘛，对不对啊？listen fd。

有时间响应的话就accept取出已连接用户通信的fd，

然后再派发到具体的工作线程上啊，工作线程event loop。

在这里边相当于就是事件分发器，好不好啊？

把它理解成这个epoll啊，

如果你反应不上来啊，事件分发器到底是啥？理解成epoll就行了。





那么。在这儿，我们来看一下啊，大家在脑子里边儿回想一想啊，

你已经学过的select编程poll编程跟epoll的编程，

最起码它的这个基本的这个编程操作呢。

啊，大家呢把它回忆一下啊，回忆一下啊，在这里边，

因为我们是讲项目啊。基本的这个网络编程呢，我们就不细说了啊，我默认大家都是知道。

他们最基础的这个编程过程啊。

## select的缺点

select跟poll的这个缺点啊，我们先看select。

#### 监听多个套接字

#### 需要把监听的套接字通过fd_set到一个位数组

大家想一想select。select一个线程，一个select可以监听很多的这个socket套接字。但是它每次都要把套接字啊，通过它的这个fd set呀设置到一个位数组当中，对吧？

#### 响应后，内核需要把位数字拷贝到用户态

响应以后呢？内核就又又要把发生事件的这个位数组呢从这个内核再拷贝到我们用户空间。

用户去遍历数组哪一个socket发生事件

对不对啊？然后我们用户空间呢，就会遍历整个的位数组来判断啊，到底呢哪一个socket发生事件了啊？

在这里边儿，我们把缺点汇总到了四点，

### 总结select四个缺点

大家一块儿来看一下

#### 文件描述符的数量呢，是受限

单个进程，能够监视的文件描述的数量存在最大的限制。通常是1024，在我们系统里边，通常是1024个是不是啊？

当然可以更改数量啊，你可以设置重新更改这个数量，

但由于select层在应用层面啊，采用的是轮询的方式来扫描。

文件描述符看哪一个文件描述发生事件了，所以你在这里边儿，如果想把这个1024也就是给你的这个宏fdsize的size调整的太大的话。

那么，在我应用层面不断的去扫描这个文件，描述服务的这个位数组的话，所花费的时间也是线性增长的。文件描述符数量越多，性能越差。

这是第一个啊，就是文件描述符的数量呢，是受限的啊。

#### 对应的poll使用的是一个链表来保存

那么poll啊，你看这个poll啊，就是在对应的poll啊，==poll它底层并没有用位数组来存储，它使用的是一个链表来保存文件描述符==的啊，

因此没有了监视文件数量的这个限制。啊，但其他三个缺陷呢，是依然存在的，也就是poll跟select它俩相比的话就是它所能操作的这个fd的数量就是我们Linux系统给每一个进程默认配置的。fd数量的上限对不对？

不像select，它是被默认设置的，这个1024给限制住了啊，

#### select涉及到内核跟用户空间大量的这个数据拷贝

第二个就是涉及的内核跟用户空间大量的这个内存拷贝问题，

因为我每次调用select的时候呢，都会去填写相应的位数组，

填写相应的这个数据，

然后呢，通过前链的的调用把这些填写好的，这个句柄数据，

这里边句柄指的就是文件描述符啊，

句柄数据拷从用户空间拷贝到内核空间。

内核的空间去监听事件是否发生，发生了以后再把发生事件的这些句柄呢？再从内核空间拷贝到用户空间啊。

所以如果这些句柄多的话，就涉及到内核跟用户空间大量的这个数据拷贝啊select，需要复制大量的句柄数据，产生了巨大的开销。

这也是一一个不好的地方啊。

### select 需要去遍历这整个句柄

第三个select返回的是含有整个句柄的数组啊，所以我们应用程序在判断呢。

应用程序在判断的时候，我们并不清楚啊到底是哪个句柄发生事件了？

我们是需要去遍历这整个句柄的，这个数组对于poll来说就是这个链表对不对？啊，才能发现了哪些句柄发生的事件？哪些句柄没有发生对不对啊？

这是第三个。



这都是我们编程上啊，直接就能看到就能碰到的这个问题。

### 水平触发导致的问题

第四个select的触发方式是水平触发。

应用程序如果没有完成一个已经就绪的文件描述符的IO操作，

那么之后每次死来的调用还是会将这些文件描述通知进程了，

意思就是说呢，如果呢select或者poll，它们默认工作的这个水平触发啊。呃，他们给你上报了这个发生事件的fd，如果你把这个文件句柄啊，socket这个句柄上的数据没有读完的话，它是不断的会给你触发的意思，

就是说触发次数多嘛，触发次数多比较浪费效率，是不是啊？

### epoll可以设置EF边沿触发

啊，当然epoll呢，默认也是工作在这个水平触发方式的，跟这里边儿描述的操作是一样的，但是epoll呢？它可以设置ET模式。

啊，就是句柄发生事件的话，内核只上报一次，所以我们应用程序需要自己去操心，把所有的数据是不都读取完成啊？

然后再回到这个epoll_wait啊。

但是这里面你要知道ET的这个模式，它的这个效率不一定就是比LT高的啊，

不一定就比LT高的，而且ET模式下它会碰见很多的问题啊，

有的只能这么说，所以在这里边儿，我们把select缺点呢，四个缺点，

我们都说了。

poll在这里边呢，没有文件描述符数量的这么一个限制，

就是第一点没有，所以poll所面临的问题呢是下边儿三点。

### select无法满足百万的并发，因为会创建1000多进程

啊，在这里边儿，我给大家写了一段话，以select的模型为例啊，

假设我们的服务器需要支持100万的并发连接。则在默认set size的1024的情况下，我们至少需要开1000个进程才能实现一每一个进程处理1024个客户啊1000个进程，大概处理100万个并发连接对吧？

1000个进程啊，我们是几乎不可能去写这样的这个后台服务程序的啊，

除非这里边是携程啊，除非这里边是携程。

1000个进程1000个线程是不现实的啊，除了进程的上下文切换非常消耗时间啊，从内核到用户控件的大量的句柄结构的内存拷贝数组，轮询等是系统难以承受的，因此基于select模型的服务器程序，我们要达到百万级别的并发访问这是非常难以完成的这么一个任务。



在这里边儿，我们总结了select的缺点，希望大家呢，把它们按点啊，好好的理解消化一下好吧啊。

## epoll原理和优势

那么epoll的这个原理以及优势是什么呢？

这里边呢，我也给大家呢，去以文字的方式呢去列了一下啊，

方便大家呢，在复习的时候呢，可以去再去看一下，再去理解一下啊。

## epoll的实现机制

底层在linux内核创建一个简易的文件系统

epoll的实现机制与select的机制完全不同啊，它们的缺点在epoll上是不复存在。

中间这一块儿呢，我还是以上面那个例子啊，来说了一下呢select跟poll的这个不足啊。

那么到我们epoll的时候，有什么不同的变化。

epoll的设计跟实现与select是完全不同的。

epoll通过在Linux内核中申请一个简易的文件系统啊，就是通过epoll_create来创建的，文件系统一般用什么数据结构？

B+树吧，就跟我们数据库里边索引一样啊它可以大大的减少我们磁盘lO的消耗啊，效率比较高。OK吧啊，效率是非常高的。

好在这儿呢，把原先的select poll调用啊，分成以下三个部分。

原来我们调用的时候就是个select或者poll调用，

### epoll的三个操作

现在呢，在epoll上我们有三个操作需要调用，

第一个是epoll_create。

调用epoll_create创了一个epoll对象啊，

实际上就是在底层呢，创建了一个啊epoll的文件系统啊，

在epoll文件系统中为这个句柄啊，对象分配相应的一些资源。

那么，这里边包括有红黑树，它底层呢，有两个数据结构，一个是红黑树啊，一个是一个双向的这么一个链表啊，双向链表，相应的数据结构啊，

## epoll对象包含两个数据结构

#### 红黑树和双向链表

开始给它分配内存初始化，对吧？然后呢，通过epoll control 向epoll对象中添加这100万个连接的套接字。

就是说呢epoll ctrl你只需要一次性的啊，向这个epoll中就是第一步添加的这个epo对象中。

添加你感兴趣相应事件的这些socket，把它都添加到底层的这个红黑树上。这个效率是很高的，红黑树的这个是是我们这个C++高级数据结构啊，

是比较重要的一个东西，大家在学习C++的时候呢，

像这个有序的关联容器map跟set底层是不是也是红黑树啊啊？

非常常用，大家知道红黑树的这个增删查是可以达到这个对手时间的是比较快啊啊，所以呢，这里边儿的效率也是非常不错。

像这个红黑树，大概呢1000万的数据的话呢，只有20层左右对不对啊？

只有20层左右，也就是说呢？你要啊，我们刚才说的1000万，这100万也就十来层左右。你往这个。底层不管是你通过epoll control，是add是modify还是delete呢？

在epoll底层的这个红黑树上，最多的花销也就是十来个节点的遍历效率是相当不错的。

然后呢，就可以开始调用epoll收集发生的这个事件啊，

当这个事件发生以后，我们底层的这个epoll呢，

会从红黑树的节点上摘录下来发生事件的节点，并把它放到哪里呀？

并把它放到这个双向链表当中。

那么，这个双向链表直接就存储了发生事件的。

#### epoll为我们返回发生事件的fd

这些事件集合在我们应用程序当中，我们不需要遍历所有的100万个套接字，看谁发生事件谁，谁没发生事件。



epoll给我们返回的就是发生事件的fd的集合。

==不像select和poll，我们需要自己去遍历啊，到底哪些是这个句柄发生事件，哪些句柄没有发生事件，对不对？==

因为我们大部分的场景都是100万的连接，但是活跃的没有几个啊，

那如果是select的的话呢，我们需要在100万个这个句柄里边儿去遍历啊，

哪些句柄发生事件呢？明显效率很低，

==而epoll呢？是epoll直接给我们返回的就是发生事件的集合。==

对不对？没有发生事件的这个句柄啊，它并没有给我们返回，是不是啊？

如此一来，要实现上面说的场景，只需要在进程启动时建立一个epoll对象。

然后在需要的时候向这个epoll对象中添加或者删除事件。就是这个event对吧啊，

#### epoll_wait

同时呢epoll_wait的效率也是非常高的啊，

因为调用epoll_wait时并没有向操作系统复制这100万个连接的这个数据句柄，内核也不需要去遍历全部的这个连接。

不需要复制吗？因为你事前都通过epoll control呢，

把这些连接相关的套接字句柄呢，是不是全部放在这个红黑树上了？

啊100万个连接的线性遍历。怎么可能跟我们红黑树的搜索来比呢嘛？

这是对数时间的100万。

在100万的数据集合里边儿搜索一个句柄，最多也就是花费十来个句柄的。这么一个搜索的时间。是不是啊？

我记得1000万的这个数据量红黑数，大概也就是个22层还是23层啊

100万个大概也就是17层18层吧，大家可以算一下log以二为底的一百万一千万就行了。

是吧啊。效率非常高，

发生事件呢，这个句柄呢，拷贝到这个双向链链表里边儿epoll wait返回的话呢，我们就可以直接拿到发生事件的fd的集合了啊，

效率比较高。

好，这就是epoll的这个原理以及优势，



我们通过在这里边啊，这么一个场景啊，我们给大家呢？

去演示了一下，说明了一下epoll的高效到底是原因是什么？

epoll在这里边默认是LT模式，跟select poll一样，

就是内核数据没有读完的话，就会一直是上报数据边缘处。

这是一个水平触发嘛，对吧啊？

水平触发就是数据没有还可读呃，没读完还数据可写，它就会一直上报。



ET模式是什么呢？

ET模式内核数据只上报一次就什么时候会上报呢？

就是从不可读到可读，从不可写到可写这个状态的变化，它上报一次。

啊，你如果不读完不写完的话，它就不会再触发了。

不会再触发一波硬跟一波的事件了，好吧啊，



我们大家呢，平时呢，就是因为逮住这么一句话

ET模式下，因为内核上报数据只上报一次，所以呢，它效率比较高一点。

## 并不是ET就一定好

对不对啊？所以一股脑的认为epoll的LT模式没有任何存在的价值，

实际上并不是这样。那你可以想一想，如果在极端的情况下。

啊，那么epoll工作在ET模式下的话呢？

一个套接字上面的数据不断的源源不断的数据过来。

因为你的ET模式socket的这个上面的数据啊，只上报一次，因为它从不可读到可读，不可写到可写，是不是才上报一次啊？

那么，你的应用程序呢？不断的去循环，从这个socket上去读数据，读数据，读数据。对不对？

那么在这个过程中，其他的有事件上报的socket，由于你的应用程序。无法及时的回到epoll的其他发生事情的socket，根本无法及时的得到你服务器的处理，你服务从客户端来。

这个体会的话就是说诶，我操作了半天，怎么没见服务器给我返回呀？

那就是客户端就会感觉啊，服务器的延时好像是很高的。

没问题吧啊，这就是一种极端的这个情况。所以呢，大家呢啊，一看muduo库模式是LT诶，

你这写的不好，你咋不用ET呢，对吧？

## muduo采用LT的原因

所以呢？LT的模式呢，实际上已经是很不错了啊，而且呢，编程简单，不易出错。

每次呢，只用读一次，没读完，下一次的话呢，内核是还会给你上报数据的，

是不是关键是它能够去平均的去处理每一个socket身上的这个读写事件，

能够及时的回到epoll wait能够雨露均沾，

让所有的socket都得到及时的处理，让客户端感觉呢，服务器延时低啊。



大家都很高兴，是不是啊？不能说ET极端模式下只高兴了，你一个人，其他人都不高兴，觉得延时很大。

所以muduo muduo库这里边儿采用的是LT模式，我们写代码的时候，

大家也可以留意一下啊。呃，muduo库采用的这个LT模式呢？

### muduo采用LT模式原因

其实原因也是很多的啊，在这里边我摘录了三个啊就是。三个原因啊，大家呢？如果有兴趣的话呢，可以在。嗯，知乎上啊，再可以再挖一挖好吧啊，挖一挖，如果你感兴趣的话。



不会丢失数据或者是消息啊，很明显这一句话你应该是能明白，对吧？

ET模式只上报一次嘛，那你数据不读完，那就没机会读了。对不对啊？

所以呢，如果你的应用程序编写呢？代码有问题的话呢？

那在这儿就会丢失数据或者消息啊，因为没有读完数据内核是不会这个应用。啊，

这里边写的是LT是吧啊？

应用没有读完数据的话，内核是不断上报的啊，我不怕这个数据或者消息被丢失了，低延迟处理就是我刚说的啊，每次读取数据时要一次系统调用，照顾了多个连接的公平性啊。



不会因为某个连接上的数据量过大而影响其他连接上的处理消息。

好吧啊。再者的话呢就是默认写的LT模式的话呢，因为像select poll啊，

都是支持的是LT模式，这样的话muduo库呢啊，

就是把跨平台处理可能会比较方便一点。

因为大家知道，在这个unix系统上啊，比如说苹果啊unix系统上，

它是没有epoll的啊，它是queen。

对不对啊？但是有select跟poll。

啊，它默认都是工作在LT模式上，

所以呢呃，从代码网络库的代码实现上工作在LT模式呢也有助于这个muduo库在这个WINDOWS或者说是linux呀跨平台的这个使用会更方便一些啊，

因为其他的系统支持LT模式的都是有的啊。



好吧啊ET模式呢，就不一定有了。

这里边儿是给了三个解释muduo库，为什么选择的是LT模式，而没有采用ET模式？



好吧啊，那么在这个奔驰Mark上啊，

在奔驰Mark上就是压力测试上。

测试这个muduo库跟libevent啊，libevent是一个用C语言写的，

这个网络库对吧？也是底层也是基于事件驱动统一事件源的。

这么一个epoll啊level event epoll呢，采用的是ET模式啊ET模式，



但是呢，从压测的这个奔驰Mark压测的结果来看啊，这个奔驰Mark不是我做的啊。这是人家专业的专专业的，这个人员专业的机构来做的啊，包括这个muduo库的作者，陈硕本身也去做了啊，大家可以在muduo库的这个主页上。

它有附这个压力测试的，这个结果在单线程情况下muduo库跟libevent的性能差不了多少，

但是在多线程。这个环境下呢muduo库它的。q PS它的这个吞吐量啊，大致可以达到libevent的近两倍啊近两倍。

所以你要说是muduo库采用LT的这个模式，采用ET模式啊，

为什么muduo库的这个LT模式的效率会更高呢？

我们说了啊，不要仅仅只是通过LT或者ET呢来判断效率高与低，

那这样的话，那LT模式是不是就没有存在的必要了啊？



而我们服务器也并不是说只测服务器的连接对不对？

我们服务器还是有业务需要处理的，加上业务处理啊，就会这里边像低延迟啊，是不是？ET模式的这个性能就会受一定的是不是影响啊？



对，所以呢，不同场景有不同的这个应用啊，所以大家也不要一味的觉得ET模式好啊ET模式好。

啊，这是一个不准确的一个认知啊。



## 总结

好了，那这一节课呢？

我主要给大家又总结了一下epoll啊，总结了一下linux的IO复用select poll。说了一下，select poll的缺点。

然后又阐述了一下epoll的这个原理以及优势，

我们说到了muduo库啊epoll的底层的这个实现原理对吧？

啊，它的LT跟ET模式，我们muduo库采用的是LT模式，

那原因有哪些呢？对吧？又给大家普及了一下muduo库跟libevent的一个压测的一个结果啊，

大家从压测结果上也能感受到muduo库设计的优秀之处。

对不对啊？还是非常不错的啊。

好，那我们这节课的内容就给大家说到这里。